# Evaluation [![Build Status](https://travis-ci.org/rai-project/evaluation.svg?branch=master)](https://travis-ci.org/rai-project/evaluation)

MLModelScope enables easy evaluations of both performance and accuracy of models across frameworks and systems.
This repo contains utility functions that help summarize and visualize the experiments results.
